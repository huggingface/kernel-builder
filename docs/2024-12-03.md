
This document contains notes about the current status of the kernel-builder and some items to explore/complete.

## Exploration

- [ ] naming collision; there are foreseeable issues with 
	- torch register
		- what happens when two versions of the same library are loaded
		- how are similar names but different signatures resolved.
	- cpp
		- separate from torch what if two libraries expose symbols with the same name?
		- repro: two modules with different names with the same function signatures?
	- python side / torch

- [ ] docker to wrap the nix builder
	- [ ] *finishing the builder is a prerequisite*

- [ ] cleaning up the builder 
	- [ ] removing flake (dev artifacts)
	- [ ] long term goal will provide the build step as a simple function
		- [ ] that function will be used in docker

- [ ] build shim
	- [ ] currently we still require `Torch` in the build process (only because) many of the kernels have Tensors in their signatures. The shim should relieve this requirement.

- [ ] checking/enumerate the flag used when compiling
	- [ ] ie flags like `__CUDA_NO_HALF_CONVERSIONS__` and `__CUDA_NO_HALF2_OPERATORS__` seem to add strictness - we should likely add
	- [ ] others like `‚Äìexpt-relaxed-constexpr` may need to be removed https://forums.developer.nvidia.com/t/check-for-expt-relaxed-constexpr/62425
	- [ ] we should explore how to define these via the `build.toml`
	- [ ] review what we NEED and what we WANT
### Example/Demo

Thank you Oliver üôè for the initial demo! Using the hub to store/load kernels is an important step in the end to end process.

- [X] proof of concept - from hub
	- [x] building specific kernel (py version/ torch version / cuda version)
	- [x] upload to hub
	- [x] access from hub
	- [x] use kernel locally

next we'll create a similar proof of concept - however with a slightly different starting point (the build process/ targeting a wide range of versions)

- [ ] end to end proof of concept
	- [x] create build harness
	- [x] building torch2.4 torch2.5 (cuda 12.4)
	- [ ] upload to hub
	- [ ] access from hub (small changes needed for new naming convention)
	- [ ] use kernel locally

### Conceptual

**documenting kernels**
- assuming we'll need a nice UI for the kernel repos - maybe we can continue to define the `build.toml` and this can be a basis for the UI elements?
- in general what do people want to know about a kernel? maybe places it used?

**configuration strictness**
- its it better to limit build options?
	- strictness is nice because it sets a standard
		- maybe we should make a standard?
	- flexibility is nice because more people can do more things 
		- but this adds complexity later...
- it would be nice to allow users to specify dependencies options (cublas, cudnn, etc) - or maybe just a subset?
  
### Socializing
- [ ] finding early partners/teams to work is very helpful
	- [ ] identify important issues
	- [ ] align with users
	- [ ] add value when first released to public

### Notes/References

- old way to bing to torch (deprecated) https://pytorch.org/tutorials/advanced/cpp_extension.html 
- newer way https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html#custom-ops-landing-page